{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ef2e27",
   "metadata": {
    "id": "f7ef2e27"
   },
   "source": [
    "# Hyperparameter search for classification with Tabular data (Keras)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deephyper/tutorials/blob/main/tutorials/colab/HPS_basic_classification_with_tabular_data/notebook.ipynb)\n",
    "\n",
    "In this tutorial we present how to use hyperparameter optimization on a basic example from the Keras documentation.\n",
    "\n",
    "**Reference**:\n",
    " This tutorial is based on materials from the Keras Documentation: [Structured data classification from scratch](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/)\n",
    "\n",
    "Let us start with installing DeepHyper!\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Warning</b>\n",
    "    \n",
    "This tutorial should be run with `tensorflow>=2.6`.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fdbc102-a0e1-4f83-ab59-24ff712df5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.2\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import deephyper\n",
    "    print(deephyper.__version__)\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    !pip install deephyper\n",
    "    \n",
    "try:\n",
    "    import ray\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    !pip install ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38664b59",
   "metadata": {
    "id": "38664b59"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Note</b>\n",
    "    \n",
    "The following environment variables can be used to avoid the logging of **some** Tensorflow *DEBUG*, *INFO* and *WARNING* statements.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320e7d27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:08:03.492690Z",
     "start_time": "2021-10-06T14:08:03.490841Z"
    },
    "id": "320e7d27",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = str(3)\n",
    "os.environ[\"AUTOGRAPH_VERBOSITY\"] = str(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22386d68",
   "metadata": {
    "id": "22386d68"
   },
   "source": [
    "## Imports\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "<b>Warning</b> \n",
    "\n",
    "It is important to follow the import strategy `import tensorflow as tf` to prevent serialization errors that will crash the search.\n",
    "    \n",
    "</div>\n",
    "\n",
    "The import strategy from the original Keras tutorial (shown below),\n",
    "\n",
    "```python\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "...\n",
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "```\n",
    "    \n",
    "resulted in non-serializable data, preventing the search from executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a37b1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:08:06.961251Z",
     "start_time": "2021-10-06T14:08:04.788328Z"
    },
    "id": "f3a37b1d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9061925",
   "metadata": {
    "id": "e9061925"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Note</b>\n",
    "    \n",
    "The following can be used to detect if <b>GPU</b> devices are available on the current host. Therefore, this notebook will automatically adapt the parallel execution based on the resources available locally. However, this simple code will not detect the ressources from multiple nodes.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da5e0602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:08:15.285962Z",
     "start_time": "2021-10-06T14:08:11.659531Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da5e0602",
    "outputId": "41f0e3bf-b2c9-4d0e-9db5-52be81ac6427",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == \"GPU\"]\n",
    "\n",
    "\n",
    "n_gpus = len(get_available_gpus())\n",
    "if n_gpus > 1:\n",
    "    n_gpus -= 1\n",
    "    \n",
    "is_gpu_available = n_gpus > 0\n",
    "\n",
    "if is_gpu_available:\n",
    "    print(f\"{n_gpus} GPU{'s are' if n_gpus > 1 else ' is'} available.\")\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c702c644",
   "metadata": {
    "id": "c702c644"
   },
   "source": [
    "## The dataset (from Keras.io)\n",
    "\n",
    "The [dataset](https://archive.ics.uci.edu/ml/datasets/heart+Disease) is provided by the\n",
    "Cleveland Clinic Foundation for Heart Disease.\n",
    "It's a CSV file with 303 rows. Each row contains information about a patient (a\n",
    "**sample**), and each column describes an attribute of the patient (a **feature**). We\n",
    "use the features to predict whether a patient has a heart disease (**binary\n",
    "classification**).\n",
    "\n",
    "Here's the description of each feature:\n",
    "\n",
    "Column| Description| Feature Type\n",
    "------------|--------------------|----------------------\n",
    "Age | Age in years | Numerical\n",
    "Sex | (1 = male; 0 = female) | Categorical\n",
    "CP | Chest pain type (0, 1, 2, 3, 4) | Categorical\n",
    "Trestbpd | Resting blood pressure (in mm Hg on admission) | Numerical\n",
    "Chol | Serum cholesterol in mg/dl | Numerical\n",
    "FBS | fasting blood sugar in 120 mg/dl (1 = true; 0 = false) | Categorical\n",
    "RestECG | Resting electrocardiogram results (0, 1, 2) | Categorical\n",
    "Thalach | Maximum heart rate achieved | Numerical\n",
    "Exang | Exercise induced angina (1 = yes; 0 = no) | Categorical\n",
    "Oldpeak | ST depression induced by exercise relative to rest | Numerical\n",
    "Slope | Slope of the peak exercise ST segment | Numerical\n",
    "CA | Number of major vessels (0-3) colored by fluoroscopy | Both numerical & categorical\n",
    "Thal | 3 = normal; 6 = fixed defect; 7 = reversible defect | Categorical\n",
    "Target | Diagnosis of heart disease (1 = true; 0 = false) | Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9499cd94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:08:19.106131Z",
     "start_time": "2021-10-06T14:08:19.102761Z"
    },
    "id": "9499cd94",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "    dataframe = pd.read_csv(file_url)\n",
    "\n",
    "    val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "    train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "    return train_dataframe, val_dataframe\n",
    "\n",
    "\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb5938",
   "metadata": {
    "id": "6ceb5938"
   },
   "source": [
    "## Preprocessing & encoding of features\n",
    "\n",
    "The next cells use `tf.keras.layers.Normalization()` to apply standard scaling on the features.\n",
    "\n",
    "Then, the `tf.keras.layers.StringLookup` and `tf.keras.layers.IntegerLookup` are used to encode categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "996814d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:08:22.308775Z",
     "start_time": "2021-10-06T14:08:22.304430Z"
    },
    "id": "996814d7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = tf.keras.layers.Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_categorical_feature(feature, name, dataset, is_string):\n",
    "    lookup_class = (\n",
    "        tf.keras.layers.StringLookup if is_string else tf.keras.layers.IntegerLookup\n",
    "    )\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8743319",
   "metadata": {
    "id": "c8743319"
   },
   "source": [
    "## Define the run-function\n",
    "\n",
    "The run-function defines how the objective that we want to maximize is computed. It takes a `config` dictionary as input and often returns a scalar value that we want to maximize. The `config` contains a sample value of hyperparameters that we want to tune. In this example we will search for:\n",
    "\n",
    "* `units` (default value: `32`)\n",
    "* `activation` (default value: `\"relu\"`)\n",
    "* `dropout_rate` (default value: `0.5`)\n",
    "* `num_epochs` (default value: `50`)\n",
    "* `batch_size` (default value: `32`)\n",
    "* `learning_rate` (default value: `1e-3`)\n",
    "\n",
    "A hyperparameter value can be acessed easily in the dictionary through the corresponding key, for example `config[\"units\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f99f031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:08:25.815920Z",
     "start_time": "2021-10-06T14:08:25.802830Z"
    },
    "id": "2f99f031",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(config: dict):\n",
    "    tf.autograph.set_verbosity(0)\n",
    "    # Load data and split into validation set\n",
    "    train_dataframe, val_dataframe = load_data()\n",
    "    train_ds = dataframe_to_dataset(train_dataframe)\n",
    "    val_ds = dataframe_to_dataset(val_dataframe)\n",
    "    train_ds = train_ds.batch(config[\"batch_size\"])\n",
    "    val_ds = val_ds.batch(config[\"batch_size\"])\n",
    "\n",
    "    # Categorical features encoded as integers\n",
    "    sex = tf.keras.Input(shape=(1,), name=\"sex\", dtype=\"int64\")\n",
    "    cp = tf.keras.Input(shape=(1,), name=\"cp\", dtype=\"int64\")\n",
    "    fbs = tf.keras.Input(shape=(1,), name=\"fbs\", dtype=\"int64\")\n",
    "    restecg = tf.keras.Input(shape=(1,), name=\"restecg\", dtype=\"int64\")\n",
    "    exang = tf.keras.Input(shape=(1,), name=\"exang\", dtype=\"int64\")\n",
    "    ca = tf.keras.Input(shape=(1,), name=\"ca\", dtype=\"int64\")\n",
    "\n",
    "    # Categorical feature encoded as string\n",
    "    thal = tf.keras.Input(shape=(1,), name=\"thal\", dtype=\"string\")\n",
    "\n",
    "    # Numerical features\n",
    "    age = tf.keras.Input(shape=(1,), name=\"age\")\n",
    "    trestbps = tf.keras.Input(shape=(1,), name=\"trestbps\")\n",
    "    chol = tf.keras.Input(shape=(1,), name=\"chol\")\n",
    "    thalach = tf.keras.Input(shape=(1,), name=\"thalach\")\n",
    "    oldpeak = tf.keras.Input(shape=(1,), name=\"oldpeak\")\n",
    "    slope = tf.keras.Input(shape=(1,), name=\"slope\")\n",
    "\n",
    "    all_inputs = [\n",
    "        sex,\n",
    "        cp,\n",
    "        fbs,\n",
    "        restecg,\n",
    "        exang,\n",
    "        ca,\n",
    "        thal,\n",
    "        age,\n",
    "        trestbps,\n",
    "        chol,\n",
    "        thalach,\n",
    "        oldpeak,\n",
    "        slope,\n",
    "    ]\n",
    "\n",
    "    # Integer categorical features\n",
    "    sex_encoded = encode_categorical_feature(sex, \"sex\", train_ds, False)\n",
    "    cp_encoded = encode_categorical_feature(cp, \"cp\", train_ds, False)\n",
    "    fbs_encoded = encode_categorical_feature(fbs, \"fbs\", train_ds, False)\n",
    "    restecg_encoded = encode_categorical_feature(restecg, \"restecg\", train_ds, False)\n",
    "    exang_encoded = encode_categorical_feature(exang, \"exang\", train_ds, False)\n",
    "    ca_encoded = encode_categorical_feature(ca, \"ca\", train_ds, False)\n",
    "\n",
    "    # String categorical features\n",
    "    thal_encoded = encode_categorical_feature(thal, \"thal\", train_ds, True)\n",
    "\n",
    "    # Numerical features\n",
    "    age_encoded = encode_numerical_feature(age, \"age\", train_ds)\n",
    "    trestbps_encoded = encode_numerical_feature(trestbps, \"trestbps\", train_ds)\n",
    "    chol_encoded = encode_numerical_feature(chol, \"chol\", train_ds)\n",
    "    thalach_encoded = encode_numerical_feature(thalach, \"thalach\", train_ds)\n",
    "    oldpeak_encoded = encode_numerical_feature(oldpeak, \"oldpeak\", train_ds)\n",
    "    slope_encoded = encode_numerical_feature(slope, \"slope\", train_ds)\n",
    "\n",
    "    all_features = tf.keras.layers.concatenate(\n",
    "        [\n",
    "            sex_encoded,\n",
    "            cp_encoded,\n",
    "            fbs_encoded,\n",
    "            restecg_encoded,\n",
    "            exang_encoded,\n",
    "            slope_encoded,\n",
    "            ca_encoded,\n",
    "            thal_encoded,\n",
    "            age_encoded,\n",
    "            trestbps_encoded,\n",
    "            chol_encoded,\n",
    "            thalach_encoded,\n",
    "            oldpeak_encoded,\n",
    "        ]\n",
    "    )\n",
    "    x = tf.keras.layers.Dense(config[\"units\"], activation=config[\"activation\"])(\n",
    "        all_features\n",
    "    )\n",
    "    x = tf.keras.layers.Dropout(config[\"dropout_rate\"])(x)\n",
    "    output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = tf.keras.Model(all_inputs, output)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
    "    model.compile(optimizer, \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds, epochs=config[\"num_epochs\"], validation_data=val_ds, verbose=0\n",
    "    )\n",
    "\n",
    "    return history.history[\"val_accuracy\"][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea800ab1",
   "metadata": {
    "id": "ea800ab1"
   },
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "<b>Note</b>  \n",
    "<br>\n",
    "\n",
    "The objective maximised by DeepHyper is the scalar value returned by the `run`-function.\n",
    "    \n",
    "</div>\n",
    "\n",
    "In this tutorial it corresponds to the validation accuracy of the last epoch of training which we retrieve in the `History` object returned by the `model.fit(...)` call.\n",
    "    \n",
    "```python\n",
    "...\n",
    "history = model.fit(\n",
    "    train_ds, epochs=config[\"num_epochs\"], validation_data=val_ds, verbose=0\n",
    ") \n",
    "return history.history[\"val_accuracy\"][-1]\n",
    "...\n",
    "``` \n",
    "    \n",
    "Using an objective like `max(history.history['val_accuracy'])` can have undesired side effects.\n",
    "\n",
    "For example, it is possible that the training curves will overshoot a local maximum, resulting in a model without the capacity to flexibly adapt to new data in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca589b5",
   "metadata": {
    "id": "3ca589b5"
   },
   "source": [
    "## Define the Hyperparameter optimization problem\n",
    "\n",
    "Hyperparameter ranges are defined using the following syntax:\n",
    "\n",
    "* Discrete integer ranges are generated from a tuple `(lower: int, upper: int)`\n",
    "* Continuous prarameters are generated from a tuple `(lower: float, upper: float)`\n",
    "* Categorical or nonordinal hyperparameter ranges can be given as a list of possible values `[val1, val2, ...]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5813bb59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:08:50.985064Z",
     "start_time": "2021-10-06T14:08:49.770713Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5813bb59",
    "outputId": "5c6260b7-2b23-4cda-a0b2-e6db07aa6177",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configuration space object:\n",
       "  Hyperparameters:\n",
       "    activation, Type: Categorical, Choices: {elu, gelu, hard_sigmoid, linear, relu, selu, sigmoid, softplus, softsign, swish, tanh}, Default: relu\n",
       "    batch_size, Type: UniformInteger, Range: [8, 256], Default: 32, on log-scale\n",
       "    dropout_rate, Type: UniformFloat, Range: [0.0, 0.6], Default: 0.5\n",
       "    learning_rate, Type: UniformFloat, Range: [1e-05, 0.01], Default: 0.001, on log-scale\n",
       "    num_epochs, Type: UniformInteger, Range: [10, 100], Default: 50\n",
       "    units, Type: UniformInteger, Range: [8, 128], Default: 32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deephyper.problem import HpProblem\n",
    "\n",
    "\n",
    "# Creation of an hyperparameter problem\n",
    "problem = HpProblem()\n",
    "\n",
    "# Discrete hyperparameter (sampled with uniform prior)\n",
    "problem.add_hyperparameter((8, 128), \"units\", default_value=32)\n",
    "problem.add_hyperparameter((10, 100), \"num_epochs\", default_value=50)\n",
    "\n",
    "\n",
    "# Categorical hyperparameter (sampled with uniform prior)\n",
    "ACTIVATIONS = [\n",
    "    \"elu\", \"gelu\", \"hard_sigmoid\", \"linear\", \"relu\", \"selu\",\n",
    "    \"sigmoid\", \"softplus\", \"softsign\", \"swish\", \"tanh\",\n",
    "]\n",
    "problem.add_hyperparameter(ACTIVATIONS, \"activation\", default_value=\"relu\")\n",
    "\n",
    "\n",
    "# Real hyperparameter (sampled with uniform prior)\n",
    "problem.add_hyperparameter((0.0, 0.6), \"dropout_rate\", default_value=0.5)\n",
    "\n",
    "\n",
    "# Discrete and Real hyperparameters (sampled with log-uniform)\n",
    "problem.add_hyperparameter((8, 256, \"log-uniform\"), \"batch_size\", default_value=32)\n",
    "problem.add_hyperparameter((1e-5, 1e-2, \"log-uniform\"), \"learning_rate\", default_value=1e-3)\n",
    "\n",
    "problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1719e4",
   "metadata": {
    "id": "9f1719e4"
   },
   "source": [
    "## Evaluate a default configuration\n",
    "\n",
    "We evaluate the performance of the default set of hyperparameters provided in the Keras tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ab7ab0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:08:49.765740Z",
     "start_time": "2021-10-06T14:08:29.330155Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ab7ab0c",
    "outputId": "52c639e6-33bd-43bb-8aea-6d1ba1036f60",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 12:17:37,785\tINFO worker.py:1509 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Default Configuration:  0.820\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "\n",
    "# We launch the Ray run-time depending of the detected local ressources\n",
    "# and execute the `run` function with the default configuration\n",
    "# WARNING: in the case of GPUs it is important to follow this scheme\n",
    "# to avoid multiple processes (Ray workers vs current process) to lock\n",
    "# the same GPU.\n",
    "if is_gpu_available:\n",
    "    if not(ray.is_initialized()):\n",
    "        ray.init(num_cpus=n_gpus, num_gpus=n_gpus, log_to_driver=False)\n",
    "    \n",
    "    run_default = ray.remote(num_cpus=1, num_gpus=1)(run)\n",
    "    objective_default = ray.get(run_default.remote(problem.default_configuration))\n",
    "else:\n",
    "    if not(ray.is_initialized()):\n",
    "        ray.init(num_cpus=1, log_to_driver=False)\n",
    "    run_default = run\n",
    "    objective_default = run_default(problem.default_configuration)\n",
    "    \n",
    "print(f\"Accuracy Default Configuration:  {objective_default:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596900f9",
   "metadata": {
    "id": "596900f9"
   },
   "source": [
    "## Define the evaluator object\n",
    "\n",
    "The `Evaluator` object allows to change the parallelization backend used by DeepHyper.  \n",
    "It is a standalone object which schedules the execution of remote tasks. All evaluators needs a `run_function` to be instantiated.  \n",
    "Then a keyword `method` defines the backend (e.g., `\"ray\"`) and the `method_kwargs` corresponds to keyword arguments of this chosen `method`.\n",
    "\n",
    "```python\n",
    "evaluator = Evaluator.create(run_function, method, method_kwargs)\n",
    "```\n",
    "\n",
    "Once created the `evaluator.num_workers` gives access to the number of available parallel workers.\n",
    "\n",
    "Finally, to submit and collect tasks to the evaluator one just needs to use the following interface:\n",
    "\n",
    "```python\n",
    "configs = [{\"units\": 8, ...}, ...]\n",
    "evaluator.submit(configs)\n",
    "...\n",
    "# To collect the first finished task (asynchronous)\n",
    "tasks_done = evaluator.get(\"BATCH\", size=1)\n",
    "\n",
    "# To collect all of the pending tasks (synchronous)\n",
    "tasks_done = evaluator.get(\"ALL\")\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Warning</b>\n",
    "\n",
    "Each `Evaluator` saves its own state, therefore it is crucial to create a new evaluator when launching a fresh search.\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3f0be13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:08:51.128103Z",
     "start_time": "2021-10-06T14:08:50.989345Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3f0be13",
    "outputId": "0ad00798-09e7-4814-f456-87603dceb1d2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new evaluator with 1 worker and config: {'num_cpus': 1, 'num_cpus_per_task': 1, 'callbacks': [<deephyper.evaluator.callback.TqdmCallback object at 0x16a8533a0>]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/romainegele/Documents/Argonne/deephyper/deephyper/evaluator/_evaluator.py:126: UserWarning: Applying nest-asyncio patch for IPython Shell!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from deephyper.evaluator import Evaluator\n",
    "from deephyper.evaluator.callback import TqdmCallback\n",
    "\n",
    "\n",
    "def get_evaluator(run_function):\n",
    "    # Default arguments for Ray: 1 worker and 1 worker per evaluation\n",
    "    method_kwargs = {\n",
    "        \"num_cpus\": 1, \n",
    "        \"num_cpus_per_task\": 1,\n",
    "        \"callbacks\": [TqdmCallback()]\n",
    "    }\n",
    "\n",
    "    # If GPU devices are detected then it will create 'n_gpus' workers\n",
    "    # and use 1 worker for each evaluation\n",
    "    if is_gpu_available:\n",
    "        method_kwargs[\"num_cpus\"] = n_gpus\n",
    "        method_kwargs[\"num_gpus\"] = n_gpus\n",
    "        method_kwargs[\"num_cpus_per_task\"] = 1\n",
    "        method_kwargs[\"num_gpus_per_task\"] = 1\n",
    "\n",
    "    evaluator = Evaluator.create(\n",
    "        run_function, \n",
    "        method=\"ray\", \n",
    "        method_kwargs=method_kwargs\n",
    "    )\n",
    "    print(f\"Created new evaluator with {evaluator.num_workers} worker{'s' if evaluator.num_workers > 1 else ''} and config: {method_kwargs}\", )\n",
    "    \n",
    "    return evaluator\n",
    "\n",
    "evaluator_1 = get_evaluator(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392998bc",
   "metadata": {
    "id": "392998bc"
   },
   "source": [
    "## Define and run the centralized Bayesian optimization search (CBO)\n",
    "\n",
    "A primary pillar of hyperparameter search in DeepHyper is given by a centralized Bayesian optimization search (henceforth CBO). CBO may be described in the following algorithm:\n",
    "\n",
    "<img src=\"https://github.com/deephyper/tutorials/blob/main/tutorials/colab/HPS_basic_classification_with_tabular_data/Figures/AMBS.png?raw=1\" width=70% align=center>\n",
    "   \n",
    "\n",
    "---\n",
    "\n",
    "Following the parallelized evaluation of these configurations, a low-fidelity and high efficiency model (henceforth \"the surrogate\") is devised to reproduce the relationship between the input variables involved in the model (i.e., the choice of hyperparameters) and the outputs (which are generally a measure of validation data accuracy).  \n",
    "\n",
    "After obtaining this surrogate of the validation accuracy, we may utilize ideas from classical methods in Bayesian optimization literature for adaptively sample the search space of hyperparameters.\n",
    "\n",
    "First, the surrogate is used to obtain an estimate for the mean value of the validation accuracy at a certain sampling location $x$ in addition to an estimated variance. The latter requirement restricts us to the use of high efficiency data-driven modeling strategies that have inbuilt variance estimates (such as a Gaussian process or Random Forest regressor).  \n",
    "\n",
    "Regions where the mean is high represent opportunities for exploitation and regions where the variance is high represent opportunities for exploration. An optimistic acquisition function called UCB can be constructed using these two quantities:\n",
    "\n",
    "$$L_{\\text{UCB}}(x) = \\mu(x) + \\kappa \\cdot \\sigma(x)$$\n",
    "\n",
    "The *unevaluated* hyperparameter configurations that *maximize* the acquisition function are chosen for the next batch of evaluations.  \n",
    "\n",
    "Note that the choice of the variance weighting parameter $\\kappa$ controls the degree of exploration in the hyperparameter search with zero indicating purely exploitation (unseen configurations where the predicted accuracy is highest will be sampled).  \n",
    "\n",
    "The top `s` configurations are selected for the new batch. The following schematic demonstrates this process:\n",
    "\n",
    "<img src=\"https://github.com/deephyper/tutorials/blob/main/tutorials/colab/HPS_basic_classification_with_tabular_data/Figures/BO_AF.png?raw=1\" width=50%>\n",
    "\n",
    "The process of obtaining `s` configurations relies on the \"constant-liar\" strategy where a sampled configuration is mapped to a dummy output given by a bulk metric of all the evaluated configurations thus far (such as the maximum, mean or median validation accuracy).  \n",
    "\n",
    "Prior to sampling the next configuration by acquisition function maximization, the surrogate is retrained with the dummy output as a data point. As the true validation accuracy becomes available for one of the sampled configurations, the dummy output is replaced and the surrogate is updated.\n",
    "\n",
    "This allows for scalable asynchronous (or batch synchronous) sampling of new hyperparameter configurations. \n",
    "\n",
    "####  Choice of surrogate model\n",
    "\n",
    "Users should note that our choice of the surrogate is given by the Random Forest regressor due to its ability to handle non-ordinal data (hyperparameter configurations may not be purely continuous or even numerical). Evidence for how they outperform other methods (such as Gaussian processes) is also available in [1]\n",
    "\n",
    "<img src=\"https://github.com/deephyper/tutorials/blob/main/tutorials/colab/HPS_basic_classification_with_tabular_data/Figures/RFR.png?raw=1\" width=33% align=left>\n",
    "\n",
    "<img src=\"https://github.com/deephyper/tutorials/blob/main/tutorials/colab/HPS_basic_classification_with_tabular_data/Figures/RFR_Superior.png?raw=1\" width=64% align=right>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613067b2",
   "metadata": {
    "id": "613067b2"
   },
   "source": [
    "### Setup CBO\n",
    "\n",
    "We create the CBO using the `problem` and `evaluator` defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09dc7abd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:08:57.225948Z",
     "start_time": "2021-10-06T14:08:57.221120Z"
    },
    "id": "09dc7abd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deephyper.search.hps import CBO\n",
    "# Uncomment the following line to show the arguments of CBO.\n",
    "# help(CBO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e00f0f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:08:58.089438Z",
     "start_time": "2021-10-06T14:08:58.087565Z"
    },
    "id": "1e00f0f0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instanciate the search with the problem and the evaluator that we created before\n",
    "\n",
    "search = CBO(problem, evaluator_1, initial_points=[problem.default_configuration])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fad52a5",
   "metadata": {
    "id": "5fad52a5"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Note</b>\n",
    "    \n",
    "All DeepHyper's search algorithm have two stopping criteria:\n",
    "    <ul> \n",
    "        <li> <code>`max_evals (int)`</code>: Defines the maximum number of evaluations that we want to perform. Default to <code>-1</code> for an infinite number.</li>\n",
    "        <li> <code>`timeout (int)`</code>: Defines a time budget (in seconds) before stopping the search. Default to <code>None</code> for an infinite time budget.</li>\n",
    "    </ul>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "457546ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:09:28.174734Z",
     "start_time": "2021-10-06T14:09:00.593517Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "457546ce",
    "outputId": "8cf5e4c3-8f17-40e7-ab55-011f30807198",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005322933197021484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 63,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53e6419903b481d9bd9cf6cea8dcfc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = search.search(max_evals=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c2dd77",
   "metadata": {
    "id": "33c2dd77"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Warning</b>\n",
    "    \n",
    "The `search` call does not output any information about the current status of the search. However, a `results.csv` file is created in the local directly and can be visualized to see finished tasks.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c54414b",
   "metadata": {
    "id": "5c54414b"
   },
   "source": [
    "The returned `results` is a Pandas Dataframe where columns starting by `\"p:\"` are hyperparameters, columns starting by `\"m:\"` are additional metadata (from the user or from the `Evaluator`) as well as the `objective` value and the `job_id`:\n",
    "\n",
    "* `job_id` is a unique identifier corresponding to the order of creation of tasks.\n",
    "* `objective` is the value returned by the run-function.\n",
    "* `m:timestamp_submit` is the time (in seconds) when the task was created by the evaluator since the creation of the evaluator.\n",
    "* `m:timestamp_gather` is the time (in seconds) when the task was received after finishing by the evaluator since the creation of the evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87bc93b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:14:09.049833Z",
     "start_time": "2021-10-06T14:14:09.038740Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "87bc93b8",
    "outputId": "620cd69a-c6b3-4444-bf0b-86c58dadc58f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p:activation</th>\n",
       "      <th>p:batch_size</th>\n",
       "      <th>p:dropout_rate</th>\n",
       "      <th>p:learning_rate</th>\n",
       "      <th>p:num_epochs</th>\n",
       "      <th>p:units</th>\n",
       "      <th>objective</th>\n",
       "      <th>job_id</th>\n",
       "      <th>m:timestamp_submit</th>\n",
       "      <th>m:timestamp_gather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0</td>\n",
       "      <td>1.673296</td>\n",
       "      <td>5.423881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elu</td>\n",
       "      <td>196</td>\n",
       "      <td>0.442914</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>33</td>\n",
       "      <td>122</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>1</td>\n",
       "      <td>5.472432</td>\n",
       "      <td>6.810891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elu</td>\n",
       "      <td>65</td>\n",
       "      <td>0.304934</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>2</td>\n",
       "      <td>6.840086</td>\n",
       "      <td>8.020196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>14</td>\n",
       "      <td>0.574456</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>55</td>\n",
       "      <td>42</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>3</td>\n",
       "      <td>8.049471</td>\n",
       "      <td>10.171254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>softplus</td>\n",
       "      <td>50</td>\n",
       "      <td>0.027865</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>51</td>\n",
       "      <td>87</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>4</td>\n",
       "      <td>10.302291</td>\n",
       "      <td>11.826399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>linear</td>\n",
       "      <td>220</td>\n",
       "      <td>0.196513</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>38</td>\n",
       "      <td>84</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>5</td>\n",
       "      <td>11.855185</td>\n",
       "      <td>13.540711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>93</td>\n",
       "      <td>0.567920</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>6</td>\n",
       "      <td>13.569894</td>\n",
       "      <td>14.862006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tanh</td>\n",
       "      <td>127</td>\n",
       "      <td>0.233563</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>74</td>\n",
       "      <td>32</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>7</td>\n",
       "      <td>14.890817</td>\n",
       "      <td>16.443914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>linear</td>\n",
       "      <td>21</td>\n",
       "      <td>0.569421</td>\n",
       "      <td>0.004058</td>\n",
       "      <td>47</td>\n",
       "      <td>84</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>8</td>\n",
       "      <td>16.472753</td>\n",
       "      <td>18.266434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relu</td>\n",
       "      <td>61</td>\n",
       "      <td>0.383737</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>9</td>\n",
       "      <td>18.295845</td>\n",
       "      <td>19.519711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p:activation  p:batch_size  p:dropout_rate  p:learning_rate  p:num_epochs  \\\n",
       "0          relu            32        0.500000         0.001000            50   \n",
       "1           elu           196        0.442914         0.000019            33   \n",
       "2           elu            65        0.304934         0.002111            19   \n",
       "3          relu            14        0.574456         0.005709            55   \n",
       "4      softplus            50        0.027865         0.000235            51   \n",
       "5        linear           220        0.196513         0.000031            38   \n",
       "6  hard_sigmoid            93        0.567920         0.000735            14   \n",
       "7          tanh           127        0.233563         0.000239            74   \n",
       "8        linear            21        0.569421         0.004058            47   \n",
       "9          relu            61        0.383737         0.000045            18   \n",
       "\n",
       "   p:units  objective  job_id  m:timestamp_submit  m:timestamp_gather  \n",
       "0       32   0.819672       0            1.673296            5.423881  \n",
       "1      122   0.540984       1            5.472432            6.810891  \n",
       "2        8   0.803279       2            6.840086            8.020196  \n",
       "3       42   0.770492       3            8.049471           10.171254  \n",
       "4       87   0.803279       4           10.302291           11.826399  \n",
       "5       84   0.704918       5           11.855185           13.540711  \n",
       "6       73   0.770492       6           13.569894           14.862006  \n",
       "7       32   0.803279       7           14.890817           16.443914  \n",
       "8       84   0.819672       8           16.472753           18.266434  \n",
       "9       14   0.557377       9           18.295845           19.519711  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd8b3e4",
   "metadata": {
    "id": "dbd8b3e4"
   },
   "source": [
    "The search can be continued without any issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e6af67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:14:10.966261Z",
     "start_time": "2021-10-06T14:14:09.918767Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "f2e6af67",
    "outputId": "179d3151-a080-46aa-d412-e8d24bc4c69f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002431154251098633,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 63,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e22917601943208872674ab416e836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p:activation</th>\n",
       "      <th>p:batch_size</th>\n",
       "      <th>p:dropout_rate</th>\n",
       "      <th>p:learning_rate</th>\n",
       "      <th>p:num_epochs</th>\n",
       "      <th>p:units</th>\n",
       "      <th>objective</th>\n",
       "      <th>job_id</th>\n",
       "      <th>m:timestamp_submit</th>\n",
       "      <th>m:timestamp_gather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0</td>\n",
       "      <td>1.673296</td>\n",
       "      <td>5.423881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elu</td>\n",
       "      <td>196</td>\n",
       "      <td>0.442914</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>33</td>\n",
       "      <td>122</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>1</td>\n",
       "      <td>5.472432</td>\n",
       "      <td>6.810891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elu</td>\n",
       "      <td>65</td>\n",
       "      <td>0.304934</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>2</td>\n",
       "      <td>6.840086</td>\n",
       "      <td>8.020196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>14</td>\n",
       "      <td>0.574456</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>55</td>\n",
       "      <td>42</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>3</td>\n",
       "      <td>8.049471</td>\n",
       "      <td>10.171254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>softplus</td>\n",
       "      <td>50</td>\n",
       "      <td>0.027865</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>51</td>\n",
       "      <td>87</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>4</td>\n",
       "      <td>10.302291</td>\n",
       "      <td>11.826399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>linear</td>\n",
       "      <td>220</td>\n",
       "      <td>0.196513</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>38</td>\n",
       "      <td>84</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>5</td>\n",
       "      <td>11.855185</td>\n",
       "      <td>13.540711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>93</td>\n",
       "      <td>0.567920</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>6</td>\n",
       "      <td>13.569894</td>\n",
       "      <td>14.862006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tanh</td>\n",
       "      <td>127</td>\n",
       "      <td>0.233563</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>74</td>\n",
       "      <td>32</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>7</td>\n",
       "      <td>14.890817</td>\n",
       "      <td>16.443914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>linear</td>\n",
       "      <td>21</td>\n",
       "      <td>0.569421</td>\n",
       "      <td>0.004058</td>\n",
       "      <td>47</td>\n",
       "      <td>84</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>8</td>\n",
       "      <td>16.472753</td>\n",
       "      <td>18.266434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relu</td>\n",
       "      <td>61</td>\n",
       "      <td>0.383737</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>9</td>\n",
       "      <td>18.295845</td>\n",
       "      <td>19.519711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>softsign</td>\n",
       "      <td>211</td>\n",
       "      <td>0.467029</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>28</td>\n",
       "      <td>50</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>10</td>\n",
       "      <td>61.149681</td>\n",
       "      <td>62.913303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>elu</td>\n",
       "      <td>27</td>\n",
       "      <td>0.571352</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>48</td>\n",
       "      <td>12</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>11</td>\n",
       "      <td>63.053085</td>\n",
       "      <td>64.710794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>elu</td>\n",
       "      <td>11</td>\n",
       "      <td>0.446366</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>53</td>\n",
       "      <td>11</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>12</td>\n",
       "      <td>64.924019</td>\n",
       "      <td>67.180369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>elu</td>\n",
       "      <td>28</td>\n",
       "      <td>0.583510</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>13</td>\n",
       "      <td>67.321455</td>\n",
       "      <td>69.016971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>elu</td>\n",
       "      <td>18</td>\n",
       "      <td>0.594079</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>67</td>\n",
       "      <td>14</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>14</td>\n",
       "      <td>69.156168</td>\n",
       "      <td>71.279930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p:activation  p:batch_size  p:dropout_rate  p:learning_rate  p:num_epochs  \\\n",
       "0           relu            32        0.500000         0.001000            50   \n",
       "1            elu           196        0.442914         0.000019            33   \n",
       "2            elu            65        0.304934         0.002111            19   \n",
       "3           relu            14        0.574456         0.005709            55   \n",
       "4       softplus            50        0.027865         0.000235            51   \n",
       "5         linear           220        0.196513         0.000031            38   \n",
       "6   hard_sigmoid            93        0.567920         0.000735            14   \n",
       "7           tanh           127        0.233563         0.000239            74   \n",
       "8         linear            21        0.569421         0.004058            47   \n",
       "9           relu            61        0.383737         0.000045            18   \n",
       "10      softsign           211        0.467029         0.000039            28   \n",
       "11           elu            27        0.571352         0.001114            48   \n",
       "12           elu            11        0.446366         0.001394            53   \n",
       "13           elu            28        0.583510         0.000013            44   \n",
       "14           elu            18        0.594079         0.006243            67   \n",
       "\n",
       "    p:units  objective  job_id  m:timestamp_submit  m:timestamp_gather  \n",
       "0        32   0.819672       0            1.673296            5.423881  \n",
       "1       122   0.540984       1            5.472432            6.810891  \n",
       "2         8   0.803279       2            6.840086            8.020196  \n",
       "3        42   0.770492       3            8.049471           10.171254  \n",
       "4        87   0.803279       4           10.302291           11.826399  \n",
       "5        84   0.704918       5           11.855185           13.540711  \n",
       "6        73   0.770492       6           13.569894           14.862006  \n",
       "7        32   0.803279       7           14.890817           16.443914  \n",
       "8        84   0.819672       8           16.472753           18.266434  \n",
       "9        14   0.557377       9           18.295845           19.519711  \n",
       "10       50   0.229508      10           61.149681           62.913303  \n",
       "11       12   0.836066      11           63.053085           64.710794  \n",
       "12       11   0.803279      12           64.924019           67.180369  \n",
       "13       17   0.393443      13           67.321455           69.016971  \n",
       "14       14   0.786885      14           69.156168           71.279930  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = search.search(max_evals=5)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d673da",
   "metadata": {
    "id": "53d673da"
   },
   "source": [
    "Now that the search is over, let us print the best configuration found during this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f906a04f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:14:10.979212Z",
     "start_time": "2021-10-06T14:14:10.975696Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f906a04f",
    "outputId": "164bfe6d-df76-4258-d55d-e7d4125d5890",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The default configuration has an accuracy of 0.820. \n",
      "The best configuration found by DeepHyper has an accuracy 0.836, \n",
      "discovered after 64.71 secondes of search.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'p:activation': 'elu',\n",
       " 'p:batch_size': 27,\n",
       " 'p:dropout_rate': 0.5713520400329467,\n",
       " 'p:learning_rate': 0.0011143178363802,\n",
       " 'p:num_epochs': 48,\n",
       " 'p:units': 12,\n",
       " 'objective': 0.8360655903816223}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_max = results.objective.argmax()\n",
    "best_config = results.iloc[i_max][:-3].to_dict()\n",
    "\n",
    "\n",
    "print(f\"The default configuration has an accuracy of {objective_default:.3f}. \\n\" \n",
    "      f\"The best configuration found by DeepHyper has an accuracy {results['objective'].iloc[i_max]:.3f}, \\n\" \n",
    "      f\"discovered after {results['m:timestamp_gather'].iloc[i_max]:.2f} secondes of search.\\n\")\n",
    "\n",
    "best_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8349d84",
   "metadata": {
    "id": "b8349d84"
   },
   "source": [
    "## Restart from a checkpoint\n",
    "\n",
    "It can often be useful to continue the search from previous results. For example, if the allocation requested was not enough or if an unexpected crash happened. The `AMBS` searhc provides the `fit_surrogate(dataframe_of_results)` method for this use case. \n",
    "\n",
    "To simulate this we create a second evaluator `evaluator_2` and start a fresh AMBS search with strong explotation `kappa=0.001`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e99249c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:14:13.791888Z",
     "start_time": "2021-10-06T14:14:13.717020Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e99249c",
    "outputId": "1782a7d9-ca6a-4485-c4b4-c8824e973e1a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new evaluator with 1 worker and config: {'num_cpus': 1, 'num_cpus_per_task': 1, 'callbacks': [<deephyper.evaluator.callback.TqdmCallback object at 0x16c69cd00>]}\n"
     ]
    }
   ],
   "source": [
    "# Create a new evaluator\n",
    "evaluator_2 = get_evaluator(run)\n",
    "\n",
    "# Create a new AMBS search with strong explotation (i.e., small kappa)\n",
    "search_from_checkpoint = CBO(problem, evaluator_2, kappa=0.001)\n",
    "\n",
    "# Initialize surrogate model of Bayesian optization (in AMBS)\n",
    "# With results of previous search\n",
    "search_from_checkpoint.fit_surrogate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9baeb24f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:15:00.807606Z",
     "start_time": "2021-10-06T14:14:15.820625Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9baeb24f",
    "outputId": "37a409ce-f61d-4941-8a97-32468370168b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0130 12:20:53.838909000 10922094592 chttp2_transport.cc:1167]         Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0024628639221191406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 63,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a03f55b2da7420fab2961d002d5a1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_from_checkpoint = search_from_checkpoint.search(max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f293587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:15:00.826885Z",
     "start_time": "2021-10-06T14:15:00.819039Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "7f293587",
    "outputId": "0b706201-1ec0-45e5-eae2-590bc05bd0c3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p:activation</th>\n",
       "      <th>p:batch_size</th>\n",
       "      <th>p:dropout_rate</th>\n",
       "      <th>p:learning_rate</th>\n",
       "      <th>p:num_epochs</th>\n",
       "      <th>p:units</th>\n",
       "      <th>objective</th>\n",
       "      <th>job_id</th>\n",
       "      <th>m:timestamp_submit</th>\n",
       "      <th>m:timestamp_gather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elu</td>\n",
       "      <td>9</td>\n",
       "      <td>0.563147</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0</td>\n",
       "      <td>4.881641</td>\n",
       "      <td>8.339313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elu</td>\n",
       "      <td>27</td>\n",
       "      <td>0.586640</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>1</td>\n",
       "      <td>8.489422</td>\n",
       "      <td>10.275765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gelu</td>\n",
       "      <td>28</td>\n",
       "      <td>0.534305</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>2</td>\n",
       "      <td>10.421549</td>\n",
       "      <td>12.151974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gelu</td>\n",
       "      <td>9</td>\n",
       "      <td>0.520566</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>48</td>\n",
       "      <td>14</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>3</td>\n",
       "      <td>12.299520</td>\n",
       "      <td>14.649483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gelu</td>\n",
       "      <td>22</td>\n",
       "      <td>0.376572</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>47</td>\n",
       "      <td>21</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>4</td>\n",
       "      <td>14.796534</td>\n",
       "      <td>16.606915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tanh</td>\n",
       "      <td>43</td>\n",
       "      <td>0.571578</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>5</td>\n",
       "      <td>16.754099</td>\n",
       "      <td>17.986947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gelu</td>\n",
       "      <td>15</td>\n",
       "      <td>0.549082</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>6</td>\n",
       "      <td>18.228396</td>\n",
       "      <td>20.232561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>elu</td>\n",
       "      <td>27</td>\n",
       "      <td>0.486335</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>83</td>\n",
       "      <td>127</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>7</td>\n",
       "      <td>20.380729</td>\n",
       "      <td>22.511694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gelu</td>\n",
       "      <td>47</td>\n",
       "      <td>0.534682</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>47</td>\n",
       "      <td>20</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>8</td>\n",
       "      <td>22.663078</td>\n",
       "      <td>24.264377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gelu</td>\n",
       "      <td>137</td>\n",
       "      <td>0.533913</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>92</td>\n",
       "      <td>21</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>9</td>\n",
       "      <td>24.420509</td>\n",
       "      <td>26.063546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p:activation  p:batch_size  p:dropout_rate  p:learning_rate  p:num_epochs  \\\n",
       "0          elu             9        0.563147         0.002584            50   \n",
       "1          elu            27        0.586640         0.001353            64   \n",
       "2         gelu            28        0.534305         0.001184            48   \n",
       "3         gelu             9        0.520566         0.002797            48   \n",
       "4         gelu            22        0.376572         0.000640            47   \n",
       "5         tanh            43        0.571578         0.001132            18   \n",
       "6         gelu            15        0.549082         0.001329            47   \n",
       "7          elu            27        0.486335         0.001134            83   \n",
       "8         gelu            47        0.534682         0.000790            47   \n",
       "9         gelu           137        0.533913         0.000648            92   \n",
       "\n",
       "   p:units  objective  job_id  m:timestamp_submit  m:timestamp_gather  \n",
       "0        8   0.786885       0            4.881641            8.339313  \n",
       "1       10   0.819672       1            8.489422           10.275765  \n",
       "2       19   0.836066       2           10.421549           12.151974  \n",
       "3       14   0.770492       3           12.299520           14.649483  \n",
       "4       21   0.819672       4           14.796534           16.606915  \n",
       "5       13   0.803279       5           16.754099           17.986947  \n",
       "6       19   0.819672       6           18.228396           20.232561  \n",
       "7      127   0.803279       7           20.380729           22.511694  \n",
       "8       20   0.852459       8           22.663078           24.264377  \n",
       "9       21   0.819672       9           24.420509           26.063546  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f28d724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:15:01.129246Z",
     "start_time": "2021-10-06T14:15:00.837350Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f28d724",
    "outputId": "28516a5b-b78e-4268-ef6d-c026a910abd4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The default configuration has an accuracy of 0.820. The best configuration found by DeepHyper has an accuracy 0.852, finished after 24.26 secondes of search.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'p:activation': 'gelu',\n",
       " 'p:batch_size': 47,\n",
       " 'p:dropout_rate': 0.5346818686230272,\n",
       " 'p:learning_rate': 0.0007899995372786,\n",
       " 'p:num_epochs': 47,\n",
       " 'p:units': 20,\n",
       " 'objective': 0.8524590134620667}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_max = results_from_checkpoint.objective.argmax()\n",
    "best_config = results_from_checkpoint.iloc[i_max][:-3].to_dict()\n",
    "\n",
    "print(f\"The default configuration has an accuracy of {objective_default:.3f}. \" \n",
    "      f\"The best configuration found by DeepHyper has an accuracy {results_from_checkpoint['objective'].iloc[i_max]:.3f}, \" \n",
    "      f\"finished after {results_from_checkpoint['m:timestamp_gather'].iloc[i_max]:.2f} secondes of search.\")\n",
    "\n",
    "best_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b535c9d",
   "metadata": {
    "id": "8b535c9d"
   },
   "source": [
    "## Add conditional hyperparameters\n",
    "\n",
    "Now we want to add the possibility to search for a second fully-connected layer. We simply add two new lines:\n",
    "\n",
    "```python\n",
    "if config.get(\"dense_2\", False):\n",
    "    x = tf.keras.layers.Dense(config[\"dense_2:units\"], activation=config[\"dense_2:activation\"])(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a62e9f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:15:01.344982Z",
     "start_time": "2021-10-06T14:15:01.141111Z"
    },
    "id": "8a62e9f5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_with_condition(config: dict):\n",
    "    tf.autograph.set_verbosity(0)\n",
    "    \n",
    "    train_dataframe, val_dataframe = load_data()\n",
    "\n",
    "    train_ds = dataframe_to_dataset(train_dataframe)\n",
    "    val_ds = dataframe_to_dataset(val_dataframe)\n",
    "\n",
    "    train_ds = train_ds.batch(config[\"batch_size\"])\n",
    "    val_ds = val_ds.batch(config[\"batch_size\"])\n",
    "\n",
    "    # Categorical features encoded as integers\n",
    "    sex = tf.keras.Input(shape=(1,), name=\"sex\", dtype=\"int64\")\n",
    "    cp = tf.keras.Input(shape=(1,), name=\"cp\", dtype=\"int64\")\n",
    "    fbs = tf.keras.Input(shape=(1,), name=\"fbs\", dtype=\"int64\")\n",
    "    restecg = tf.keras.Input(shape=(1,), name=\"restecg\", dtype=\"int64\")\n",
    "    exang = tf.keras.Input(shape=(1,), name=\"exang\", dtype=\"int64\")\n",
    "    ca = tf.keras.Input(shape=(1,), name=\"ca\", dtype=\"int64\")\n",
    "\n",
    "    # Categorical feature encoded as string\n",
    "    thal = tf.keras.Input(shape=(1,), name=\"thal\", dtype=\"string\")\n",
    "\n",
    "    # Numerical features\n",
    "    age = tf.keras.Input(shape=(1,), name=\"age\")\n",
    "    trestbps = tf.keras.Input(shape=(1,), name=\"trestbps\")\n",
    "    chol = tf.keras.Input(shape=(1,), name=\"chol\")\n",
    "    thalach = tf.keras.Input(shape=(1,), name=\"thalach\")\n",
    "    oldpeak = tf.keras.Input(shape=(1,), name=\"oldpeak\")\n",
    "    slope = tf.keras.Input(shape=(1,), name=\"slope\")\n",
    "\n",
    "    all_inputs = [\n",
    "        sex,\n",
    "        cp,\n",
    "        fbs,\n",
    "        restecg,\n",
    "        exang,\n",
    "        ca,\n",
    "        thal,\n",
    "        age,\n",
    "        trestbps,\n",
    "        chol,\n",
    "        thalach,\n",
    "        oldpeak,\n",
    "        slope,\n",
    "    ]\n",
    "\n",
    "    # Integer categorical features\n",
    "    sex_encoded = encode_categorical_feature(sex, \"sex\", train_ds, False)\n",
    "    cp_encoded = encode_categorical_feature(cp, \"cp\", train_ds, False)\n",
    "    fbs_encoded = encode_categorical_feature(fbs, \"fbs\", train_ds, False)\n",
    "    restecg_encoded = encode_categorical_feature(restecg, \"restecg\", train_ds, False)\n",
    "    exang_encoded = encode_categorical_feature(exang, \"exang\", train_ds, False)\n",
    "    ca_encoded = encode_categorical_feature(ca, \"ca\", train_ds, False)\n",
    "\n",
    "    # String categorical features\n",
    "    thal_encoded = encode_categorical_feature(thal, \"thal\", train_ds, True)\n",
    "\n",
    "    # Numerical features\n",
    "    age_encoded = encode_numerical_feature(age, \"age\", train_ds)\n",
    "    trestbps_encoded = encode_numerical_feature(trestbps, \"trestbps\", train_ds)\n",
    "    chol_encoded = encode_numerical_feature(chol, \"chol\", train_ds)\n",
    "    thalach_encoded = encode_numerical_feature(thalach, \"thalach\", train_ds)\n",
    "    oldpeak_encoded = encode_numerical_feature(oldpeak, \"oldpeak\", train_ds)\n",
    "    slope_encoded = encode_numerical_feature(slope, \"slope\", train_ds)\n",
    "\n",
    "    all_features = tf.keras.layers.concatenate(\n",
    "        [\n",
    "            sex_encoded,\n",
    "            cp_encoded,\n",
    "            fbs_encoded,\n",
    "            restecg_encoded,\n",
    "            exang_encoded,\n",
    "            slope_encoded,\n",
    "            ca_encoded,\n",
    "            thal_encoded,\n",
    "            age_encoded,\n",
    "            trestbps_encoded,\n",
    "            chol_encoded,\n",
    "            thalach_encoded,\n",
    "            oldpeak_encoded,\n",
    "        ]\n",
    "    )\n",
    "    x = tf.keras.layers.Dense(config[\"units\"], activation=config[\"activation\"])(\n",
    "        all_features\n",
    "    )\n",
    "\n",
    "    ### START - NEW LINES\n",
    "    if config.get(\"dense_2\", False):\n",
    "        x = tf.keras.layers.Dense(config[\"dense_2:units\"], activation=config[\"dense_2:activation\"])(x)\n",
    "    ### END - NEW LINES\n",
    "\n",
    "    x = tf.keras.layers.Dropout(config[\"dropout_rate\"])(x)\n",
    "    output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = tf.keras.Model(all_inputs, output)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
    "    model.compile(optimizer, \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds, epochs=config[\"num_epochs\"], validation_data=val_ds, verbose=0\n",
    "    )\n",
    "\n",
    "    return history.history[\"val_accuracy\"][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df1c9fb",
   "metadata": {
    "id": "5df1c9fb"
   },
   "source": [
    "To define conditionnal hyperparameters we use [ConfigSpace](https://automl.github.io/ConfigSpace/master/index.html). We define `dense_2:units` and `dense_2:activation` as active hyperparameters only when `dense_2 == True`. The `cs.EqualsCondition` help us do that. Then we call\n",
    "\n",
    "```python\n",
    "problem_with_condition.add_condition(condition)\n",
    "```\n",
    "\n",
    "to register each new condition to the `HpProblem`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cda0275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:15:41.846465Z",
     "start_time": "2021-10-06T14:15:41.831051Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cda0275",
    "outputId": "6b0c9ec6-7dec-4fce-8a8d-090b380411fc",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configuration space object:\n",
       "  Hyperparameters:\n",
       "    activation, Type: Categorical, Choices: {elu, gelu, hard_sigmoid, linear, relu, selu, sigmoid, softplus, softsign, swish, tanh}, Default: elu\n",
       "    batch_size, Type: UniformInteger, Range: [8, 256], Default: 45, on log-scale\n",
       "    dense_2, Type: Categorical, Choices: {True, False}, Default: True\n",
       "    dense_2:activation, Type: Categorical, Choices: {elu, gelu, hard_sigmoid, linear, relu, selu, sigmoid, softplus, softsign, swish, tanh}, Default: elu\n",
       "    dense_2:units, Type: UniformInteger, Range: [8, 128], Default: 68\n",
       "    dropout_rate, Type: UniformFloat, Range: [0.0, 0.6], Default: 0.3\n",
       "    learning_rate, Type: UniformFloat, Range: [1e-05, 0.01], Default: 0.0003162278, on log-scale\n",
       "    num_epochs, Type: UniformInteger, Range: [10, 100], Default: 55\n",
       "    units, Type: UniformInteger, Range: [8, 128], Default: 68\n",
       "  Conditions:\n",
       "    dense_2:activation | dense_2 == True\n",
       "    dense_2:units | dense_2 == True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deephyper.problem import EqualsCondition\n",
    "\n",
    "# Define the hyperparameter problem\n",
    "problem_with_condition = HpProblem()\n",
    "\n",
    "\n",
    "# Define the same hyperparameters as before\n",
    "problem_with_condition.add_hyperparameter((8, 128), \"units\")\n",
    "problem_with_condition.add_hyperparameter(ACTIVATIONS, \"activation\")\n",
    "problem_with_condition.add_hyperparameter((0.0, 0.6), \"dropout_rate\")\n",
    "problem_with_condition.add_hyperparameter((10, 100), \"num_epochs\")\n",
    "problem_with_condition.add_hyperparameter((8, 256, \"log-uniform\"), \"batch_size\")\n",
    "problem_with_condition.add_hyperparameter((1e-5, 1e-2, \"log-uniform\"), \"learning_rate\")\n",
    "\n",
    "\n",
    "# Add a new hyperparameter \"dense_2 (bool)\" to decide if a second fully-connected layer should be created\n",
    "hp_dense_2 = problem_with_condition.add_hyperparameter([True, False], \"dense_2\")\n",
    "hp_dense_2_units = problem_with_condition.add_hyperparameter((8, 128), \"dense_2:units\")\n",
    "hp_dense_2_activation = problem_with_condition.add_hyperparameter(ACTIVATIONS, \"dense_2:activation\")\n",
    "\n",
    "problem_with_condition.add_condition(EqualsCondition(hp_dense_2_units, hp_dense_2, True))\n",
    "problem_with_condition.add_condition(EqualsCondition(hp_dense_2_activation, hp_dense_2, True))\n",
    "\n",
    "\n",
    "problem_with_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc027194",
   "metadata": {
    "id": "fc027194"
   },
   "source": [
    "We create a new evaluator `evaluator_3` and start a fresh AMBS search with this new problem `problem_with_condition`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70192b13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T14:15:44.701082Z",
     "start_time": "2021-10-06T14:15:44.697400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70192b13",
    "outputId": "0120bd99-3331-4160-a0ac-ec0d259a5793",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new evaluator with 1 worker and config: {'num_cpus': 1, 'num_cpus_per_task': 1, 'callbacks': [<deephyper.evaluator.callback.TqdmCallback object at 0x17e3c8250>]}\n"
     ]
    }
   ],
   "source": [
    "evaluator_3 = get_evaluator(run_with_condition)\n",
    "\n",
    "search_with_condition = CBO(problem_with_condition, evaluator_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7705a8a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T17:39:39.208415Z",
     "start_time": "2021-10-05T17:38:35.828400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7705a8a1",
    "outputId": "fb19dd74-832d-464a-9b23-414cc89b9678",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002643108367919922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 63,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7474b2d9de748c9bc689463fce68479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_with_condition = search_with_condition.search(max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4764b947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T17:39:39.253697Z",
     "start_time": "2021-10-05T17:39:39.235644Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "4764b947",
    "outputId": "3ad6ada2-e753-44dd-dfe8-1188e2f08eb6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p:activation</th>\n",
       "      <th>p:batch_size</th>\n",
       "      <th>p:dense_2</th>\n",
       "      <th>p:dropout_rate</th>\n",
       "      <th>p:learning_rate</th>\n",
       "      <th>p:num_epochs</th>\n",
       "      <th>p:units</th>\n",
       "      <th>p:dense_2:activation</th>\n",
       "      <th>p:dense_2:units</th>\n",
       "      <th>objective</th>\n",
       "      <th>job_id</th>\n",
       "      <th>m:timestamp_submit</th>\n",
       "      <th>m:timestamp_gather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gelu</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>0.522131</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0</td>\n",
       "      <td>1.576017</td>\n",
       "      <td>3.662161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>softsign</td>\n",
       "      <td>47</td>\n",
       "      <td>True</td>\n",
       "      <td>0.377181</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>47</td>\n",
       "      <td>127</td>\n",
       "      <td>elu</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>1</td>\n",
       "      <td>3.888727</td>\n",
       "      <td>5.539755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333931</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>2</td>\n",
       "      <td>5.759022</td>\n",
       "      <td>7.123170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>softsign</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>0.203617</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>77</td>\n",
       "      <td>24</td>\n",
       "      <td>softplus</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>3</td>\n",
       "      <td>7.439673</td>\n",
       "      <td>11.098140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tanh</td>\n",
       "      <td>232</td>\n",
       "      <td>False</td>\n",
       "      <td>0.544339</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>4</td>\n",
       "      <td>11.318734</td>\n",
       "      <td>12.497572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>linear</td>\n",
       "      <td>31</td>\n",
       "      <td>True</td>\n",
       "      <td>0.431446</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>27</td>\n",
       "      <td>114</td>\n",
       "      <td>tanh</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>5</td>\n",
       "      <td>12.721716</td>\n",
       "      <td>14.184543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>swish</td>\n",
       "      <td>185</td>\n",
       "      <td>True</td>\n",
       "      <td>0.143728</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>36</td>\n",
       "      <td>126</td>\n",
       "      <td>relu</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>6</td>\n",
       "      <td>14.402191</td>\n",
       "      <td>15.902531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>selu</td>\n",
       "      <td>85</td>\n",
       "      <td>True</td>\n",
       "      <td>0.513058</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>elu</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>7</td>\n",
       "      <td>16.216778</td>\n",
       "      <td>17.592724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>softplus</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>0.541869</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>44</td>\n",
       "      <td>123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>8</td>\n",
       "      <td>17.817622</td>\n",
       "      <td>19.283510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "      <td>0.221024</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>77</td>\n",
       "      <td>101</td>\n",
       "      <td>selu</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>9</td>\n",
       "      <td>19.503178</td>\n",
       "      <td>21.415980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p:activation  p:batch_size  p:dense_2  p:dropout_rate  p:learning_rate  \\\n",
       "0          gelu            24      False        0.522131         0.001057   \n",
       "1      softsign            47       True        0.377181         0.000019   \n",
       "2  hard_sigmoid            25      False        0.333931         0.000461   \n",
       "3      softsign             8       True        0.203617         0.000153   \n",
       "4          tanh           232      False        0.544339         0.000236   \n",
       "5        linear            31       True        0.431446         0.002055   \n",
       "6         swish           185       True        0.143728         0.000066   \n",
       "7          selu            85       True        0.513058         0.000975   \n",
       "8      softplus           256      False        0.541869         0.000032   \n",
       "9  hard_sigmoid            57       True        0.221024         0.000014   \n",
       "\n",
       "   p:num_epochs  p:units p:dense_2:activation  p:dense_2:units  objective  \\\n",
       "0            44        8                  NaN              NaN   0.852459   \n",
       "1            47      127                  elu             75.0   0.770492   \n",
       "2            12       33                  NaN              NaN   0.770492   \n",
       "3            77       24             softplus             20.0   0.819672   \n",
       "4            17       15                  NaN              NaN   0.377049   \n",
       "5            27      114                 tanh             69.0   0.803279   \n",
       "6            36      126                 relu             88.0   0.786885   \n",
       "7            20       24                  elu             77.0   0.836066   \n",
       "8            44      123                  NaN              NaN   0.229508   \n",
       "9            77      101                 selu             56.0   0.770492   \n",
       "\n",
       "   job_id  m:timestamp_submit  m:timestamp_gather  \n",
       "0       0            1.576017            3.662161  \n",
       "1       1            3.888727            5.539755  \n",
       "2       2            5.759022            7.123170  \n",
       "3       3            7.439673           11.098140  \n",
       "4       4           11.318734           12.497572  \n",
       "5       5           12.721716           14.184543  \n",
       "6       6           14.402191           15.902531  \n",
       "7       7           16.216778           17.592724  \n",
       "8       8           17.817622           19.283510  \n",
       "9       9           19.503178           21.415980  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_with_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ca8219",
   "metadata": {
    "id": "63ca8219"
   },
   "source": [
    "Finally, let us print out the best configuration found from this conditionned search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34f26be4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T17:39:41.791938Z",
     "start_time": "2021-10-05T17:39:41.784904Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34f26be4",
    "outputId": "df2acd84-1cf1-4ece-ad03-6fce02d5d72e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The default configuration has an accuracy of 0.820. The best configuration found by DeepHyper has an accuracy 0.852, finished after 3.66 seconds of search.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'p:activation': 'gelu',\n",
       " 'p:batch_size': 24,\n",
       " 'p:dense_2': False,\n",
       " 'p:dropout_rate': 0.5221310827728567,\n",
       " 'p:learning_rate': 0.0010573740607372,\n",
       " 'p:num_epochs': 44,\n",
       " 'p:units': 8,\n",
       " 'p:dense_2:activation': nan,\n",
       " 'p:dense_2:units': nan,\n",
       " 'objective': 0.8524590134620667}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_max = results_with_condition.objective.argmax()\n",
    "best_config = results_with_condition.iloc[i_max][:-3].to_dict()\n",
    "\n",
    "print(f\"The default configuration has an accuracy of {objective_default:.3f}. \" \n",
    "      f\"The best configuration found by DeepHyper has an accuracy {results_with_condition['objective'].iloc[i_max]:.3f}, \" \n",
    "      f\"finished after {results_with_condition['m:timestamp_gather'].iloc[i_max]:.2f} seconds of search.\")\n",
    "\n",
    "best_config"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "tutorial_01.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "9dc039a2a4f4ad8a9dc018393b0776cc00e1bb4d428a37e9ad776085656c6f7f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": ""
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
